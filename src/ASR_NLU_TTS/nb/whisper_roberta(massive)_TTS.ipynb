{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ea744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d22ecfe7",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "### - ASR [whisper(OpenAI)](https://github.com/openai/whisper)\n",
    "### - NLU [thkkvui/xlm-roberta-base-finetuned-massive](https://huggingface.co/thkkvui/xlm-roberta-base-finetuned-massive)\n",
    "### - Record [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "### - TTS [TTS(coqui-ai)](https://github.com/coqui-ai/TTS)\n",
    "### - [kunishou/Talking_Robot(GitHub)](https://github.com/kunishou/Talking_Robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb0d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0905ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq pip\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q torch\n",
    "!pip install -q pyaudio\n",
    "!pip install -q mecab-python3\n",
    "!pip install -q alkana\n",
    "!pip install -q unidic-lite\n",
    "!pip install -q TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6ab0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3494ba7f",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "asr_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b6a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf90b40e",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba6a8f",
   "metadata": {},
   "source": [
    "### load model (from huggingface hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4518eb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"thkkvui/xlm-roberta-base-finetuned-massive\"\n",
    "nlu_model = (AutoModelForSequenceClassification.from_pretrained(model_name).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91df775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'datetime_query',\n",
       " 1: 'iot_hue_lightchange',\n",
       " 2: 'transport_ticket',\n",
       " 3: 'takeaway_query',\n",
       " 4: 'qa_stock',\n",
       " 5: 'general_greet',\n",
       " 6: 'recommendation_events',\n",
       " 7: 'music_dislikeness',\n",
       " 8: 'iot_wemo_off',\n",
       " 9: 'cooking_recipe',\n",
       " 10: 'qa_currency',\n",
       " 11: 'transport_traffic',\n",
       " 12: 'general_quirky',\n",
       " 13: 'weather_query',\n",
       " 14: 'audio_volume_up',\n",
       " 15: 'email_addcontact',\n",
       " 16: 'takeaway_order',\n",
       " 17: 'email_querycontact',\n",
       " 18: 'iot_hue_lightup',\n",
       " 19: 'recommendation_locations',\n",
       " 20: 'play_audiobook',\n",
       " 21: 'lists_createoradd',\n",
       " 22: 'news_query',\n",
       " 23: 'alarm_query',\n",
       " 24: 'iot_wemo_on',\n",
       " 25: 'general_joke',\n",
       " 26: 'qa_definition',\n",
       " 27: 'social_query',\n",
       " 28: 'music_settings',\n",
       " 29: 'audio_volume_other',\n",
       " 30: 'calendar_remove',\n",
       " 31: 'iot_hue_lightdim',\n",
       " 32: 'calendar_query',\n",
       " 33: 'email_sendemail',\n",
       " 34: 'iot_cleaning',\n",
       " 35: 'audio_volume_down',\n",
       " 36: 'play_radio',\n",
       " 37: 'cooking_query',\n",
       " 38: 'datetime_convert',\n",
       " 39: 'qa_maths',\n",
       " 40: 'iot_hue_lightoff',\n",
       " 41: 'iot_hue_lighton',\n",
       " 42: 'transport_query',\n",
       " 43: 'music_likeness',\n",
       " 44: 'email_query',\n",
       " 45: 'play_music',\n",
       " 46: 'audio_volume_mute',\n",
       " 47: 'social_post',\n",
       " 48: 'alarm_set',\n",
       " 49: 'qa_factoid',\n",
       " 50: 'calendar_set',\n",
       " 51: 'play_game',\n",
       " 52: 'alarm_remove',\n",
       " 53: 'lists_remove',\n",
       " 54: 'transport_taxi',\n",
       " 55: 'recommendation_movies',\n",
       " 56: 'iot_coffee',\n",
       " 57: 'music_query',\n",
       " 58: 'play_podcasts',\n",
       " 59: 'lists_query'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlu_model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c43ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd1bb1c",
   "metadata": {},
   "source": [
    "## ÊÄßËÉΩÁ¢∫Ë™ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44601032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'weather_query', 'score': 0.9735569953918457}]\n",
      "[{'label': 'news_query', 'score': 0.9358323812484741}]\n",
      "[{'label': 'calendar_query', 'score': 0.9178861975669861}]\n",
      "[{'label': 'qa_currency', 'score': 0.8823915719985962}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=model_name)\n",
    "\n",
    "text = [\"‰ªäÊó•„ÅÆÂ§©Ê∞ó„ÇíÊïô„Åà„Å¶\", \"„Éã„É•„Éº„Çπ„ÅÇ„ÇãÔºü\", \"‰∫àÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶\", \"„Éâ„É´ÂÜÜ„ÅØÔºü\"]\n",
    "\n",
    "for t in text:\n",
    "    output = classifier(t)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6e651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aac281c",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8f2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example utterances\n",
    "\n",
    "# \"‰ªäÊó•„ÅÆÂ§©Ê∞ó„ÇíÊïô„Åà„Å¶\"\n",
    "# \"„Éã„É•„Éº„Çπ„ÅÇ„ÇãÔºü\"\n",
    "# \"‰∫àÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶Ôºü\"\n",
    "# \"„Éâ„É´ÂÜÜ„ÅØÔºü\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2179ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak to your microphone for 8 sec...\n",
      "Great!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "record_time = 8\n",
    "record_filepath = \"record.wav\"\n",
    "\n",
    "FORMAT = pyaudio.paInt16        \n",
    "rate = 44100\n",
    "chunk = 2**10\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    input=True,\n",
    "                    rate=rate, \n",
    "                    frames_per_buffer=chunk,\n",
    "                    channels=1,\n",
    ")\n",
    "\n",
    "print(f\"Speak to your microphone for {record_time} sec...\")\n",
    "frames = []\n",
    "for i in range(0, int(rate / chunk * record_time)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data) \n",
    "print (\"Great!\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(record_filepath, 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf48a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c3cdb4",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28576ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text = asr_model.transcribe(record_filepath, verbose=False, language=\"ja\")\n",
    "print(f'{asr_text[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30f0bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„Éâ„É´ „Ç®„É≥ „ÅÆ ÂÄ§ÊÆµ „ÅØ \n",
      "\n",
      "  word  en_word katakana\n",
      "0   „Éâ„É´    False     None\n",
      "1   „Ç®„É≥    False     None\n",
      "2    „ÅÆ    False     None\n",
      "3   ÂÄ§ÊÆµ    False     None\n",
      "4    „ÅØ    False     None\n",
      "5   \\n    False     None\n",
      " \n",
      "„Éâ„É´„Ç®„É≥„ÅÆÂÄ§ÊÆµ„ÅØ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import alkana\n",
    "import pandas as pd\n",
    "\n",
    "# „Éà„Éº„ÇØ„É≥Âåñ\n",
    "al_re = re.compile(r'^[a-zA-Z]+$')\n",
    "def is_al(text):\n",
    "    return al_re.match(text) is not None\n",
    "\n",
    "tmp_text = asr_text[\"text\"] #\"hello„ÉÜ„É¨„Éì„ÇíË¶ã„Åæ„Åó„Åü\"\n",
    "wakati = MeCab.Tagger('-Owakati')\n",
    "wakati_output = wakati.parse(tmp_text)\n",
    "print(wakati_output)\n",
    "\n",
    "\n",
    "# Ëã±Ë™ûÊ§úÁ¥¢\n",
    "df = pd.DataFrame(wakati_output.split(\" \"),columns=[\"word\"])\n",
    "df[\"en_word\"] = df[\"word\"].apply(is_al)\n",
    "df[\"katakana\"] = df[\"word\"].apply(alkana.get_kana)\n",
    "print(df)\n",
    "print(\" \")\n",
    "# „Ç´„Çø„Ç´„ÉäÂ§âÊèõ\n",
    "df = df[df[\"en_word\"] == True]\n",
    "dict_rep = dict(zip(df[\"word\"], df[\"katakana\"]))\n",
    "\n",
    "if len(df) > 0:\n",
    "    for word, katakana in dict_rep.items():\n",
    "        asr_text = tmp_text.replace(word, katakana)\n",
    "else:\n",
    "    asr_text = tmp_text\n",
    "    \n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dded2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318bad36",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d754b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tts_models/multilingual/multi-dataset/xtts_v1',\n",
       " 'tts_models/multilingual/multi-dataset/your_tts',\n",
       " 'tts_models/multilingual/multi-dataset/bark',\n",
       " 'tts_models/bg/cv/vits',\n",
       " 'tts_models/cs/cv/vits',\n",
       " 'tts_models/da/cv/vits',\n",
       " 'tts_models/et/cv/vits',\n",
       " 'tts_models/ga/cv/vits',\n",
       " 'tts_models/en/ek1/tacotron2',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC_ph',\n",
       " 'tts_models/en/ljspeech/glow-tts',\n",
       " 'tts_models/en/ljspeech/speedy-speech',\n",
       " 'tts_models/en/ljspeech/tacotron2-DCA',\n",
       " 'tts_models/en/ljspeech/vits',\n",
       " 'tts_models/en/ljspeech/vits--neon',\n",
       " 'tts_models/en/ljspeech/fast_pitch',\n",
       " 'tts_models/en/ljspeech/overflow',\n",
       " 'tts_models/en/ljspeech/neural_hmm',\n",
       " 'tts_models/en/vctk/vits',\n",
       " 'tts_models/en/vctk/fast_pitch',\n",
       " 'tts_models/en/sam/tacotron-DDC',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c50',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c150_v2',\n",
       " 'tts_models/en/multi-dataset/tortoise-v2',\n",
       " 'tts_models/en/jenny/jenny',\n",
       " 'tts_models/es/mai/tacotron2-DDC',\n",
       " 'tts_models/es/css10/vits',\n",
       " 'tts_models/fr/mai/tacotron2-DDC',\n",
       " 'tts_models/fr/css10/vits',\n",
       " 'tts_models/uk/mai/glow-tts',\n",
       " 'tts_models/uk/mai/vits',\n",
       " 'tts_models/zh-CN/baker/tacotron2-DDC-GST',\n",
       " 'tts_models/nl/mai/tacotron2-DDC',\n",
       " 'tts_models/nl/css10/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DCA',\n",
       " 'tts_models/de/thorsten/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DDC',\n",
       " 'tts_models/de/css10/vits-neon',\n",
       " 'tts_models/ja/kokoro/tacotron2-DDC',\n",
       " 'tts_models/tr/common-voice/glow-tts',\n",
       " 'tts_models/it/mai_female/glow-tts',\n",
       " 'tts_models/it/mai_female/vits',\n",
       " 'tts_models/it/mai_male/glow-tts',\n",
       " 'tts_models/it/mai_male/vits',\n",
       " 'tts_models/ewe/openbible/vits',\n",
       " 'tts_models/hau/openbible/vits',\n",
       " 'tts_models/lin/openbible/vits',\n",
       " 'tts_models/tw_akuapem/openbible/vits',\n",
       " 'tts_models/tw_asante/openbible/vits',\n",
       " 'tts_models/yor/openbible/vits',\n",
       " 'tts_models/hu/css10/vits',\n",
       " 'tts_models/el/cv/vits',\n",
       " 'tts_models/fi/css10/vits',\n",
       " 'tts_models/hr/cv/vits',\n",
       " 'tts_models/lt/cv/vits',\n",
       " 'tts_models/lv/cv/vits',\n",
       " 'tts_models/mt/cv/vits',\n",
       " 'tts_models/pl/mai_female/vits',\n",
       " 'tts_models/pt/cv/vits',\n",
       " 'tts_models/ro/cv/vits',\n",
       " 'tts_models/sk/cv/vits',\n",
       " 'tts_models/sl/cv/vits',\n",
       " 'tts_models/sv/cv/vits',\n",
       " 'tts_models/ca/custom/vits',\n",
       " 'tts_models/fa/custom/glow-tts',\n",
       " 'tts_models/bn/custom/vits-male',\n",
       " 'tts_models/bn/custom/vits-female',\n",
       " 'tts_models/be/common-voice/glow-tts']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS()\n",
    "tts.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32ce88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Japanese\n",
    "tts_model = tts.list_models()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2354dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model\n",
    "tts = TTS(tts_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dfe86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8adff556",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d37144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outputs = {\"weather_query\":\"‰ªäÊó•„ÅØÊô¥„Çå„ÄÅ‰∫àÊÉ≥ÊúÄÈ´òÊ∞óÊ∏©„ÅØ21‚ÑÉ„Åß„Åô„ÄÇ\",\n",
    "                 \"news_query\":\"„Ç™„É™„É≥„Éî„ÉÉ„ÇØÈô∏‰∏ä100„É°„Éº„Éà„É´Ê±∫Âãù„ÅØÈõ®Â§©È†ÜÂª∂„Å®„Å™„Çä„Åæ„Åó„Åü„ÄÇ\",\n",
    "                 \"qa_currency\":\"‰ªäÊó•„ÅÆ„Éâ„É´ÂÜÜ„ÅØ150ÂÜÜ„Åß„Åô„ÄÇ\",\n",
    "                 \"calendar_query\":\"12ÊôÇ„Åã„Çâ‰ºöË≠∞„ÄÅ17ÊôÇ„Åã„ÇâÊù±‰∫¨„Åß‰ºöÈ£ü„ÄÅ„Åå‰∫àÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d21940fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"thkkvui/xlm-roberta-base-finetuned-massive\"\n",
    "classifier = pipeline(\"text-classification\", model=model_name)\n",
    "\n",
    "output = classifier(asr_text)\n",
    "answer_text = sample_outputs[output[0][\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "211e8f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‰ªäÊó•„ÅÆ„Éâ„É´ÂÜÜ„ÅØ150ÂÜÜ„Åß„Åô„ÄÇ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a7ec0",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cae25f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['‰ªäÊó•„ÅÆ„Éâ„É´ÂÜÜ„ÅØ150ÂÜÜ„Åß„Åô„ÄÇ']\n",
      " > Processing time: 0.3338449001312256\n",
      " > Real-time factor: 0.11499125293510254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_filepath = \"output.wav\"\n",
    "tts.tts_to_file(answer_text, file_path=tts_filepath, progress_bar=False, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "183486ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "\n",
    "def sound():\n",
    "    y, sr = librosa.load(tts_filepath)\n",
    "    return IPython.display.Audio(data=y, rate=sr)\n",
    "\n",
    "sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636fbc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
