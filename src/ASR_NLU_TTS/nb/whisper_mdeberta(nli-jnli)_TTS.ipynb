{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d22ecfe7",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "### - ASR [whisper(OpenAI)](https://github.com/openai/whisper)\n",
    "### - NLU [thkkvui/mDeBERTa-v3-base-finetuned-nli-jnli](https://huggingface.co/thkkvui/mDeBERTa-v3-base-finetuned-nli-jnli)\n",
    "### - Record [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "### - TTS [TTS(coqui-ai)](https://github.com/coqui-ai/TTS)\n",
    "### - [kunishou/Talking_Robot(GitHub)](https://github.com/kunishou/Talking_Robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb0d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0905ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq pip\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets\n",
    "!pip install -q torch\n",
    "!pip install -q pyaudio\n",
    "!pip install -q mecab-python3\n",
    "!pip install -q alkana\n",
    "!pip install -q unidic-lite\n",
    "!pip install -q TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6ab0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab639bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3494ba7f",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "asr_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b6a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf90b40e",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba6a8f",
   "metadata": {},
   "source": [
    "### load model (from huggingface hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4518eb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"thkkvui/mDeBERTa-v3-base-finetuned-nli-jnli\"\n",
    "nlu_model = (AutoModelForSequenceClassification.from_pretrained(model_name).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971670ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd1bb1c",
   "metadata": {},
   "source": [
    "## ÊÄßËÉΩÁ¢∫Ë™ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f044b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Â§©Ê∞ó\", \"„Éã„É•„Éº„Çπ\", \"‰∫àÂÆö\", \"„Éû„Éº„Ç±„ÉÉ„Éà\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44601032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"thkkvui/mDeBERTa-v3-base-finetuned-nli-jnli\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "text = [\"‰ªäÊó•„ÅÆÂ§©Ê∞ó„ÇíÊïô„Åà„Å¶\", \"„Éã„É•„Éº„Çπ„ÅÇ„ÇãÔºü\", \"‰∫àÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶\", \"„Éâ„É´ÂÜÜ„ÅØÔºü\"]\n",
    "\n",
    "for t in text:\n",
    "    output = classifier(t, labels, multi_label=False)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6e651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aac281c",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8f2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example utterances \n",
    "\n",
    "# \"‰ªäÊó•„ÅÆÂ§©Ê∞ó„ÇíÊïô„Åà„Å¶\"\n",
    "# \"„Éã„É•„Éº„Çπ„ÅÇ„ÇãÔºü\"\n",
    "# \"‰∫àÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶Ôºü\"\n",
    "# \"„Éâ„É´ÂÜÜ„ÅØÔºü\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2179ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "record_time = 8\n",
    "record_filepath = \"record.wav\"\n",
    "\n",
    "FORMAT = pyaudio.paInt16        \n",
    "rate = 44100\n",
    "chunk = 2**10\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    input=True,\n",
    "                    rate=rate, \n",
    "                    frames_per_buffer=chunk,\n",
    "                    channels=1,\n",
    ")\n",
    "\n",
    "print(f\"Speak to your microphone for {record_time} sec...\")\n",
    "frames = []\n",
    "for i in range(0, int(rate / chunk * record_time)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data) \n",
    "print (\"Great!\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(record_filepath, 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf48a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c3cdb4",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28576ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text = asr_model.transcribe(record_filepath, verbose=False, language=\"ja\")\n",
    "print(f'{asr_text[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f0bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‰∫àÂÆö „Çí „ÉÅ„Çß„ÉÉ„ÇØ „Åó „Å¶ \n",
      "\n",
      "   word  en_word katakana\n",
      "0    ‰∫àÂÆö    False     None\n",
      "1     „Çí    False     None\n",
      "2  „ÉÅ„Çß„ÉÉ„ÇØ    False     None\n",
      "3     „Åó    False     None\n",
      "4     „Å¶    False     None\n",
      "5    \\n    False     None\n",
      " \n",
      "‰∫àÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„Å¶\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import alkana\n",
    "import pandas as pd\n",
    "\n",
    "# „Éà„Éº„ÇØ„É≥Âåñ\n",
    "al_re = re.compile(r'^[a-zA-Z]+$')\n",
    "def is_al(text):\n",
    "    return al_re.match(text) is not None\n",
    "\n",
    "tmp_text = asr_text[\"text\"] #\"hello„ÉÜ„É¨„Éì„ÇíË¶ã„Åæ„Åó„Åü\"\n",
    "wakati = MeCab.Tagger('-Owakati')\n",
    "wakati_output = wakati.parse(tmp_text)\n",
    "print(wakati_output)\n",
    "\n",
    "\n",
    "# Ëã±Ë™ûÊ§úÁ¥¢\n",
    "df = pd.DataFrame(wakati_output.split(\" \"),columns=[\"word\"])\n",
    "df[\"en_word\"] = df[\"word\"].apply(is_al)\n",
    "df[\"katakana\"] = df[\"word\"].apply(alkana.get_kana)\n",
    "print(df)\n",
    "print(\" \")\n",
    "# „Ç´„Çø„Ç´„ÉäÂ§âÊèõ\n",
    "df = df[df[\"en_word\"] == True]\n",
    "dict_rep = dict(zip(df[\"word\"], df[\"katakana\"]))\n",
    "\n",
    "if len(df) > 0:\n",
    "    for word, katakana in dict_rep.items():\n",
    "        asr_text = tmp_text.replace(word, katakana)\n",
    "else:\n",
    "    asr_text = tmp_text\n",
    "    \n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dded2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318bad36",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d2b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tts_models/multilingual/multi-dataset/xtts_v1',\n",
       " 'tts_models/multilingual/multi-dataset/your_tts',\n",
       " 'tts_models/multilingual/multi-dataset/bark',\n",
       " 'tts_models/bg/cv/vits',\n",
       " 'tts_models/cs/cv/vits',\n",
       " 'tts_models/da/cv/vits',\n",
       " 'tts_models/et/cv/vits',\n",
       " 'tts_models/ga/cv/vits',\n",
       " 'tts_models/en/ek1/tacotron2',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC_ph',\n",
       " 'tts_models/en/ljspeech/glow-tts',\n",
       " 'tts_models/en/ljspeech/speedy-speech',\n",
       " 'tts_models/en/ljspeech/tacotron2-DCA',\n",
       " 'tts_models/en/ljspeech/vits',\n",
       " 'tts_models/en/ljspeech/vits--neon',\n",
       " 'tts_models/en/ljspeech/fast_pitch',\n",
       " 'tts_models/en/ljspeech/overflow',\n",
       " 'tts_models/en/ljspeech/neural_hmm',\n",
       " 'tts_models/en/vctk/vits',\n",
       " 'tts_models/en/vctk/fast_pitch',\n",
       " 'tts_models/en/sam/tacotron-DDC',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c50',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c150_v2',\n",
       " 'tts_models/en/multi-dataset/tortoise-v2',\n",
       " 'tts_models/en/jenny/jenny',\n",
       " 'tts_models/es/mai/tacotron2-DDC',\n",
       " 'tts_models/es/css10/vits',\n",
       " 'tts_models/fr/mai/tacotron2-DDC',\n",
       " 'tts_models/fr/css10/vits',\n",
       " 'tts_models/uk/mai/glow-tts',\n",
       " 'tts_models/uk/mai/vits',\n",
       " 'tts_models/zh-CN/baker/tacotron2-DDC-GST',\n",
       " 'tts_models/nl/mai/tacotron2-DDC',\n",
       " 'tts_models/nl/css10/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DCA',\n",
       " 'tts_models/de/thorsten/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DDC',\n",
       " 'tts_models/de/css10/vits-neon',\n",
       " 'tts_models/ja/kokoro/tacotron2-DDC',\n",
       " 'tts_models/tr/common-voice/glow-tts',\n",
       " 'tts_models/it/mai_female/glow-tts',\n",
       " 'tts_models/it/mai_female/vits',\n",
       " 'tts_models/it/mai_male/glow-tts',\n",
       " 'tts_models/it/mai_male/vits',\n",
       " 'tts_models/ewe/openbible/vits',\n",
       " 'tts_models/hau/openbible/vits',\n",
       " 'tts_models/lin/openbible/vits',\n",
       " 'tts_models/tw_akuapem/openbible/vits',\n",
       " 'tts_models/tw_asante/openbible/vits',\n",
       " 'tts_models/yor/openbible/vits',\n",
       " 'tts_models/hu/css10/vits',\n",
       " 'tts_models/el/cv/vits',\n",
       " 'tts_models/fi/css10/vits',\n",
       " 'tts_models/hr/cv/vits',\n",
       " 'tts_models/lt/cv/vits',\n",
       " 'tts_models/lv/cv/vits',\n",
       " 'tts_models/mt/cv/vits',\n",
       " 'tts_models/pl/mai_female/vits',\n",
       " 'tts_models/pt/cv/vits',\n",
       " 'tts_models/ro/cv/vits',\n",
       " 'tts_models/sk/cv/vits',\n",
       " 'tts_models/sl/cv/vits',\n",
       " 'tts_models/sv/cv/vits',\n",
       " 'tts_models/ca/custom/vits',\n",
       " 'tts_models/fa/custom/glow-tts',\n",
       " 'tts_models/bn/custom/vits-male',\n",
       " 'tts_models/bn/custom/vits-female',\n",
       " 'tts_models/be/common-voice/glow-tts']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS()\n",
    "tts.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ce88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Japanese\n",
    "tts_model = tts.list_models()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2354dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model\n",
    "tts = TTS(tts_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dfe86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8adff556",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d37144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Â§©Ê∞ó\", \"„Éã„É•„Éº„Çπ\", \"‰∫àÂÆö\", \"„Éû„Éº„Ç±„ÉÉ„Éà\"]\n",
    "\n",
    "sample_outputs = {\"Â§©Ê∞ó\":\"‰ªäÊó•„ÅØÊô¥„Çå„ÄÅ‰∫àÊÉ≥ÊúÄÈ´òÊ∞óÊ∏©„ÅØ21‚ÑÉ„Åß„Åô„ÄÇ\",\n",
    "                  \"„Éã„É•„Éº„Çπ\":\"„Ç™„É™„É≥„Éî„ÉÉ„ÇØÈô∏‰∏ä100„É°„Éº„Éà„É´Ê±∫Âãù„ÅØÈõ®Â§©È†ÜÂª∂„Å®„Å™„Çä„Åæ„Åó„Åü„ÄÇ\",\n",
    "                  \"„Éû„Éº„Ç±„ÉÉ„Éà\":\"‰ªäÊó•„ÅÆ„Éâ„É´ÂÜÜ„ÅØ150ÂÜÜ„Åß„Åô„ÄÇ\",\n",
    "                  \"‰∫àÂÆö\":\"12ÊôÇ„Åã„Çâ‰ºöË≠∞„ÄÅ17ÊôÇ„Åã„ÇâÊù±‰∫¨„Åß‰ºöÈ£ü„ÄÅ„Åå‰∫àÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d21940fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"thkkvui/mDeBERTa-v3-base-finetuned-nli-jnli\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "output = classifier(asr_text, labels, multi_label=False)\n",
    "answer_text = sample_outputs[output[\"labels\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "211e8f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12ÊôÇ„Åã„Çâ‰ºöË≠∞„ÄÅ17ÊôÇ„Åã„ÇâÊù±‰∫¨„Åß‰ºöÈ£ü„ÄÅ„Åå‰∫àÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7caa07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "165a7ec0",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae25f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['12ÊôÇ„Åã„Çâ‰ºöË≠∞„ÄÅ17ÊôÇ„Åã„ÇâÊù±‰∫¨„Åß‰ºöÈ£ü„ÄÅ„Åå‰∫àÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ']\n",
      " > Processing time: 0.665740966796875\n",
      " > Real-time factor: 0.12224840371311703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_filepath = \"output.wav\"\n",
    "tts.tts_to_file(answer_text, file_path=tts_filepath, progress_bar=False, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "183486ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "\n",
    "def sound():\n",
    "    y, sr = librosa.load(tts_filepath)\n",
    "    return IPython.display.Audio(data=y, rate=sr)\n",
    "\n",
    "sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
