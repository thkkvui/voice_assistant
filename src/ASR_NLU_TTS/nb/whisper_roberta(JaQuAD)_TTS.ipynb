{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45a5c68",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "### - ASR [whisper(OpenAI)](https://github.com/openai/whisper)\n",
    "### - NLU [thkkvui/xlm-roberta-base-finetuned-JaQuAD(HuggingFace)](https://huggingface.co/thkkvui/xlm-roberta-base-finetuned-JaQuAD)\n",
    "### - Record [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "### - TTS [TTS(coqui-ai)](https://github.com/coqui-ai/TTS)\n",
    "### - [kunishou/Talking_Robot(GitHub)](https://github.com/kunishou/Talking_Robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06528ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8be5b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q torch\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0bf861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835ddd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1415fad",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "asr_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "090204b2",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e279b05",
   "metadata": {},
   "source": [
    "### load model (from huggingface hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e32f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"thkkvui/xlm-roberta-base-finetuned-JaQuAD\"\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(model_name).to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7f46b",
   "metadata": {},
   "source": [
    "### load model (from local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a5b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(\"./output\").to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c832aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d2c87",
   "metadata": {},
   "source": [
    "## ÊÄßËÉΩÁ¢∫Ë™ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28457fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ë≥™Âïè: Êò®Êó•„ÅØ„Å©„Åì„Å∏Âá∫„Åã„Åë„Åæ„Åó„Åü„ÅãÔºü -> ÂõûÁ≠î: Â∏ØÂ∫É\n",
      "Ë≥™Âïè: „ÅÇ„Å™„Åü„ÅÆÂêçÂâç„ÅØ‰Ωï„Åß„Åô„ÅãÔºü -> ÂõûÁ≠î: Èü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà\n",
      "Ë≥™Âïè: ‰ΩïÊ≠≥„Åß„Åô„ÅãÔºü -> ÂõûÁ≠î: 5Ê≠≥\n",
      "Ë≥™Âïè: „ÅÇ„Å™„Åü„ÅÆË∂£Âë≥„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ -> ÂõûÁ≠î: „Ç´„Éå„Éº\n",
      "Ë≥™Âïè: „ÅÇ„Å™„Åü„ÅåÂ•Ω„Åç„Å™„Ç§„Éô„É≥„Éà„ÅØ‰Ωï„Åß„Åô„ÅãÔºü -> ÂõûÁ≠î: „Éê„É´„Éº„É≥„Éï„Çß„Çπ„ÉÜ„Ç£„Éê„É´\n"
     ]
    }
   ],
   "source": [
    "text = \"ÁßÅ„ÅØÈü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇ„Åì„ÅÆ7Êúà„Åß5Ê≠≥„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ‰ªäÊú≠Âπå„Å´‰Ωè„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇÊò®Êó•„ÅØÂ∏ØÂ∫É„Å´Âá∫„Åã„Åë„Åæ„Åó„Åü„ÄÇÂ•Ω„Åç„Å™„Ç§„Éô„É≥„Éà„ÅØ„Éê„É´„Éº„É≥„Éï„Çß„Çπ„ÉÜ„Ç£„Éê„É´„Åß„Åô„ÄÇÂ•Ω„Åç„Å™È£ü„ÅπÁâ©„ÅØ„Éê„Çø„Éº„ÇØ„ÉÉ„Ç≠„Éº„ÅßË∂£Âë≥„ÅØ„Ç´„Éå„Éº„Åß„Åô„ÄÇ\"\n",
    "questions = [\"Êò®Êó•„ÅØ„Å©„Åì„Å∏Âá∫„Åã„Åë„Åæ„Åó„Åü„ÅãÔºü\", \"„ÅÇ„Å™„Åü„ÅÆÂêçÂâç„ÅØ‰Ωï„Åß„Åô„ÅãÔºü\", \"‰ΩïÊ≠≥„Åß„Åô„ÅãÔºü\", \"„ÅÇ„Å™„Åü„ÅÆË∂£Âë≥„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\",  \"„ÅÇ„Å™„Åü„ÅåÂ•Ω„Åç„Å™„Ç§„Éô„É≥„Éà„ÅØ‰Ωï„Åß„Åô„ÅãÔºü\"]\n",
    "\n",
    "for question in questions:\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = nlu_model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    print(f\"Ë≥™Âïè: {question} -> ÂõûÁ≠î: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc99430",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "832e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "\n",
    "!pip install -q pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d048ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions\n",
    "\n",
    "# \"Êò®Êó•„ÅØ„Å©„Åì„Å∏Âá∫„Åã„Åë„Åæ„Åó„Åü„ÅãÔºü\"\n",
    "# \"„ÅÇ„Å™„Åü„ÅÆÂêçÂâç„ÅØ‰Ωï„Åß„Åô„ÅãÔºü\"\n",
    "# \"‰ΩïÊ≠≥„Åß„Åô„ÅãÔºü\"\n",
    "# \"„ÅÇ„Å™„Åü„ÅÆË∂£Âë≥„ÇíÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
    "# \"„ÅÇ„Å™„Åü„ÅåÂ•Ω„Åç„Å™„Ç§„Éô„É≥„Éà„ÅØ‰Ωï„Åß„Åô„ÅãÔºü\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6c6ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak to your microphone for 8 sec...\n",
      "Great!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "record_time = 8\n",
    "record_filepath = \"record.wav\"\n",
    "\n",
    "FORMAT = pyaudio.paInt16        \n",
    "rate = 44100\n",
    "chunk = 2**10\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    input=True,\n",
    "                    rate=rate, \n",
    "                    frames_per_buffer=chunk,\n",
    "                    channels=1,\n",
    ")\n",
    "\n",
    "print(f\"Speak to your microphone for {record_time} sec...\")\n",
    "frames = []\n",
    "for i in range(0, int(rate / chunk * record_time)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data) \n",
    "print (\"Great!\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(record_filepath, 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c8853-c1c9-41c6-b184-a784857aa55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c6d458d",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d77154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "\n",
    "!pip install -q mecab-python3\n",
    "!pip install -q alkana\n",
    "!pip install -q unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd64c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text = asr_model.transcribe(record_filepath, verbose=False, language=\"ja\")\n",
    "print(f'{asr_text[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82352927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "„ÅÇ„Å™„Åü „ÅÆ ÂêçÂâç „ÅØ \n",
      "\n",
      "  word  en_word katakana\n",
      "0  „ÅÇ„Å™„Åü    False     None\n",
      "1    „ÅÆ    False     None\n",
      "2   ÂêçÂâç    False     None\n",
      "3    „ÅØ    False     None\n",
      "4   \\n    False     None\n",
      " \n",
      "„ÅÇ„Å™„Åü„ÅÆÂêçÂâç„ÅØ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import alkana\n",
    "import pandas as pd\n",
    "\n",
    "# „Éà„Éº„ÇØ„É≥Âåñ\n",
    "al_re = re.compile(r'^[a-zA-Z]+$')\n",
    "def is_al(text):\n",
    "    return al_re.match(text) is not None\n",
    "\n",
    "tmp_text = asr_text[\"text\"] #\"hello„ÉÜ„É¨„Éì„ÇíË¶ã„Åæ„Åó„Åü\"\n",
    "wakati = MeCab.Tagger('-Owakati')\n",
    "wakati_output = wakati.parse(tmp_text)\n",
    "print(wakati_output)\n",
    "\n",
    "\n",
    "# Ëã±Ë™ûÊ§úÁ¥¢\n",
    "df = pd.DataFrame(wakati_output.split(\" \"),columns=[\"word\"])\n",
    "df[\"en_word\"] = df[\"word\"].apply(is_al)\n",
    "df[\"katakana\"] = df[\"word\"].apply(alkana.get_kana)\n",
    "print(df)\n",
    "print(\" \")\n",
    "# „Ç´„Çø„Ç´„ÉäÂ§âÊèõ\n",
    "df = df[df[\"en_word\"] == True]\n",
    "dict_rep = dict(zip(df[\"word\"], df[\"katakana\"]))\n",
    "\n",
    "if len(df) > 0:\n",
    "    for word, katakana in dict_rep.items():\n",
    "        asr_text = tmp_text.replace(word, katakana)\n",
    "else:\n",
    "    asr_text = tmp_text\n",
    "    \n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152c5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b868f6b",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a45b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂøÖË¶Å„Å™„É¢„Ç∏„É•„Éº„É´„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\n",
    "\n",
    "!pip install -q TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0da8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      "0: tts_models/multilingual/multi-dataset/your_tts\n",
      "1: tts_models/multilingual/multi-dataset/bark\n",
      "2: tts_models/bg/cv/vits\n",
      "3: tts_models/cs/cv/vits\n",
      "4: tts_models/da/cv/vits\n",
      "5: tts_models/et/cv/vits\n",
      "6: tts_models/ga/cv/vits\n",
      "7: tts_models/en/ek1/tacotron2\n",
      "8: tts_models/en/ljspeech/tacotron2-DDC\n",
      "9: tts_models/en/ljspeech/tacotron2-DDC_ph\n",
      "10: tts_models/en/ljspeech/glow-tts\n",
      "11: tts_models/en/ljspeech/speedy-speech\n",
      "12: tts_models/en/ljspeech/tacotron2-DCA\n",
      "13: tts_models/en/ljspeech/vits\n",
      "14: tts_models/en/ljspeech/vits--neon\n",
      "15: tts_models/en/ljspeech/fast_pitch\n",
      "16: tts_models/en/ljspeech/overflow\n",
      "17: tts_models/en/ljspeech/neural_hmm\n",
      "18: tts_models/en/vctk/vits\n",
      "19: tts_models/en/vctk/fast_pitch\n",
      "20: tts_models/en/sam/tacotron-DDC\n",
      "21: tts_models/en/blizzard2013/capacitron-t2-c50\n",
      "22: tts_models/en/blizzard2013/capacitron-t2-c150_v2\n",
      "23: tts_models/en/multi-dataset/tortoise-v2\n",
      "24: tts_models/en/jenny/jenny\n",
      "25: tts_models/es/mai/tacotron2-DDC\n",
      "26: tts_models/es/css10/vits\n",
      "27: tts_models/fr/mai/tacotron2-DDC\n",
      "28: tts_models/fr/css10/vits\n",
      "29: tts_models/uk/mai/glow-tts\n",
      "30: tts_models/uk/mai/vits\n",
      "31: tts_models/zh-CN/baker/tacotron2-DDC-GST\n",
      "32: tts_models/nl/mai/tacotron2-DDC\n",
      "33: tts_models/nl/css10/vits\n",
      "34: tts_models/de/thorsten/tacotron2-DCA\n",
      "35: tts_models/de/thorsten/vits\n",
      "36: tts_models/de/thorsten/tacotron2-DDC\n",
      "37: tts_models/de/css10/vits-neon\n",
      "38: tts_models/ja/kokoro/tacotron2-DDC\n",
      "39: tts_models/tr/common-voice/glow-tts\n",
      "40: tts_models/it/mai_female/glow-tts\n",
      "41: tts_models/it/mai_female/vits\n",
      "42: tts_models/it/mai_male/glow-tts\n",
      "43: tts_models/it/mai_male/vits\n",
      "44: tts_models/ewe/openbible/vits\n",
      "45: tts_models/hau/openbible/vits\n",
      "46: tts_models/lin/openbible/vits\n",
      "47: tts_models/tw_akuapem/openbible/vits\n",
      "48: tts_models/tw_asante/openbible/vits\n",
      "49: tts_models/yor/openbible/vits\n",
      "50: tts_models/hu/css10/vits\n",
      "51: tts_models/el/cv/vits\n",
      "52: tts_models/fi/css10/vits\n",
      "53: tts_models/hr/cv/vits\n",
      "54: tts_models/lt/cv/vits\n",
      "55: tts_models/lv/cv/vits\n",
      "56: tts_models/mt/cv/vits\n",
      "57: tts_models/pl/mai_female/vits\n",
      "58: tts_models/pt/cv/vits\n",
      "59: tts_models/ro/cv/vits\n",
      "60: tts_models/sk/cv/vits\n",
      "61: tts_models/sl/cv/vits\n",
      "62: tts_models/sv/cv/vits\n",
      "63: tts_models/ca/custom/vits\n",
      "64: tts_models/fa/custom/glow-tts\n",
      "65: tts_models/bn/custom/vits-male\n",
      "66: tts_models/bn/custom/vits-female\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "for i, name in enumerate(TTS.list_models()[:]):\n",
    "    print(f\"{i}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c2bcd3-1b9e-4e44-a6bd-082f7b7289a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Japanese\n",
    "tts_model = TTS.list_models()[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c30be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/ja/kokoro/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/ja/kokoro/hifigan_v1 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/tthkky/Library/Application Support/tts/tts_models--ja--kokoro--tacotron2-DDC/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 3\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/tthkky/Library/Application Support/tts/vocoder_models--ja--kokoro--hifigan_v1/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# Download model\n",
    "tts = TTS(tts_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a3eeb-fccf-4e0b-a5c5-f2c075dbc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49da2ec7-f732-49f4-85ae-6ccc6724dfbd",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6b418f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Èü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "\n",
    "inputs = tokenizer.encode_plus(asr_text, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = nlu_model(**inputs)\n",
    "\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "answer_text = tokenizer.decode(answer_tokens)\n",
    "\n",
    "answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99be18dc-7865-4d1f-800a-5e1c59f8e6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: ÁßÅ„ÅØÈü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇ„Åì„ÅÆ7Êúà„Åß5Ê≠≥„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ‰ªäÊú≠Âπå„Å´‰Ωè„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇÊò®Êó•„ÅØÂ∏ØÂ∫É„Å´Âá∫„Åã„Åë„Åæ„Åó„Åü„ÄÇÂ•Ω„Åç„Å™„Ç§„Éô„É≥„Éà„ÅØ„Éê„É´„Éº„É≥„Éï„Çß„Çπ„ÉÜ„Ç£„Éê„É´„Åß„Åô„ÄÇÂ•Ω„Åç„Å™È£ü„ÅπÁâ©„ÅØ„Éê„Çø„Éº„ÇØ„ÉÉ„Ç≠„Éº„ÅßË∂£Âë≥„ÅØ„Ç´„Éå„Éº„Åß„Åô„ÄÇ\n",
      "question: „ÅÇ„Å™„Åü„ÅÆÂêçÂâç„ÅØ\n",
      "answer: Èü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà\n"
     ]
    }
   ],
   "source": [
    "print(f\"text: {text}\")\n",
    "print(f\"question: {asr_text}\")\n",
    "print(f\"answer: {answer_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe75212-0c22-4c03-93c5-b8279f6ea219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7385301f-bb0f-45f5-84ec-b81bfd6b165c",
   "metadata": {},
   "source": [
    "### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b86ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Èü≥Â£∞„Ç¢„Ç∑„Çπ„Çø„É≥„Éà']\n",
      " > Processing time: 0.353074312210083\n",
      " > Real-time factor: 0.1767455635722923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_filepath = \"output.wav\"\n",
    "tts.tts_to_file(answer_text, file_path=tts_filepath, progress_bar=False, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd30ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "\n",
    "def sound():\n",
    "    y, sr = librosa.load(tts_filepath)\n",
    "    return IPython.display.Audio(data=y, rate=sr)\n",
    "\n",
    "sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
