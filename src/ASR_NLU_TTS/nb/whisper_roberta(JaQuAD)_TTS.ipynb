{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45a5c68",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "### - ASR [whisper(OpenAI)](https://github.com/openai/whisper)\n",
    "### - NLU [thkkvui/xlm-roberta-base-finetuned-JaQuAD(HuggingFace)](https://huggingface.co/thkkvui/xlm-roberta-base-finetuned-JaQuAD)\n",
    "### - Record [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/)\n",
    "### - TTS [TTS(coqui-ai)](https://github.com/coqui-ai/TTS)\n",
    "### - [kunishou/Talking_Robot(GitHub)](https://github.com/kunishou/Talking_Robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06528ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8be5b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q torch\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0bf861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5835ddd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1415fad",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "asr_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "090204b2",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e279b05",
   "metadata": {},
   "source": [
    "### load model (from huggingface hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e32f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"thkkvui/xlm-roberta-base-finetuned-JaQuAD\"\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(model_name).to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7f46b",
   "metadata": {},
   "source": [
    "### load model (from local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a5b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(\"./output\").to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c832aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d2c87",
   "metadata": {},
   "source": [
    "## 性能確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28457fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問: 昨日はどこへ出かけましたか？ -> 回答: 帯広\n",
      "質問: あなたの名前は何ですか？ -> 回答: 音声アシスタント\n",
      "質問: 何歳ですか？ -> 回答: 5歳\n",
      "質問: あなたの趣味を教えてください。 -> 回答: カヌー\n",
      "質問: あなたが好きなイベントは何ですか？ -> 回答: バルーンフェスティバル\n"
     ]
    }
   ],
   "source": [
    "text = \"私は音声アシスタントです。この7月で5歳になりました。今札幌に住んでいます。昨日は帯広に出かけました。好きなイベントはバルーンフェスティバルです。好きな食べ物はバタークッキーで趣味はカヌーです。\"\n",
    "questions = [\"昨日はどこへ出かけましたか？\", \"あなたの名前は何ですか？\", \"何歳ですか？\", \"あなたの趣味を教えてください。\",  \"あなたが好きなイベントは何ですか？\"]\n",
    "\n",
    "for question in questions:\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = nlu_model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    print(f\"質問: {question} -> 回答: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc99430",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "832e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d048ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions\n",
    "\n",
    "# \"昨日はどこへ出かけましたか？\"\n",
    "# \"あなたの名前は何ですか？\"\n",
    "# \"何歳ですか？\"\n",
    "# \"あなたの趣味を教えてください。\"\n",
    "# \"あなたが好きなイベントは何ですか？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6c6ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak to your microphone for 8 sec...\n",
      "Great!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "record_time = 8\n",
    "record_filepath = \"record.wav\"\n",
    "\n",
    "FORMAT = pyaudio.paInt16        \n",
    "rate = 44100\n",
    "chunk = 2**10\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    input=True,\n",
    "                    rate=rate, \n",
    "                    frames_per_buffer=chunk,\n",
    "                    channels=1,\n",
    ")\n",
    "\n",
    "print(f\"Speak to your microphone for {record_time} sec...\")\n",
    "frames = []\n",
    "for i in range(0, int(rate / chunk * record_time)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data) \n",
    "print (\"Great!\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(record_filepath, 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c8853-c1c9-41c6-b184-a784857aa55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c6d458d",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d77154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q mecab-python3\n",
    "!pip install -q alkana\n",
    "!pip install -q unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd64c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text = asr_model.transcribe(record_filepath, verbose=False, language=\"ja\")\n",
    "print(f'{asr_text[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82352927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなた の 名前 は \n",
      "\n",
      "  word  en_word katakana\n",
      "0  あなた    False     None\n",
      "1    の    False     None\n",
      "2   名前    False     None\n",
      "3    は    False     None\n",
      "4   \\n    False     None\n",
      " \n",
      "あなたの名前は\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import alkana\n",
    "import pandas as pd\n",
    "\n",
    "# トークン化\n",
    "al_re = re.compile(r'^[a-zA-Z]+$')\n",
    "def is_al(text):\n",
    "    return al_re.match(text) is not None\n",
    "\n",
    "tmp_text = asr_text[\"text\"] #\"helloテレビを見ました\"\n",
    "wakati = MeCab.Tagger('-Owakati')\n",
    "wakati_output = wakati.parse(tmp_text)\n",
    "print(wakati_output)\n",
    "\n",
    "\n",
    "# 英語検索\n",
    "df = pd.DataFrame(wakati_output.split(\" \"),columns=[\"word\"])\n",
    "df[\"en_word\"] = df[\"word\"].apply(is_al)\n",
    "df[\"katakana\"] = df[\"word\"].apply(alkana.get_kana)\n",
    "print(df)\n",
    "print(\" \")\n",
    "# カタカナ変換\n",
    "df = df[df[\"en_word\"] == True]\n",
    "dict_rep = dict(zip(df[\"word\"], df[\"katakana\"]))\n",
    "\n",
    "if len(df) > 0:\n",
    "    for word, katakana in dict_rep.items():\n",
    "        asr_text = tmp_text.replace(word, katakana)\n",
    "else:\n",
    "    asr_text = tmp_text\n",
    "    \n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152c5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b868f6b",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a45b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1fe02",
   "metadata": {},
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS()\n",
    "tts.list_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c2bcd3-1b9e-4e44-a6bd-082f7b7289a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for 🐸Coqui Studio voices - https://coqui.ai \n",
      "Visit 🔗https://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Japanese\n",
    "tts_model = tts.list_models()[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c30be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/ja/kokoro/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/ja/kokoro/hifigan_v1 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/tthkky/Library/Application Support/tts/tts_models--ja--kokoro--tacotron2-DDC/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 3\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/Users/tthkky/Library/Application Support/tts/vocoder_models--ja--kokoro--hifigan_v1/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# Download model\n",
    "tts = TTS(tts_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a3eeb-fccf-4e0b-a5c5-f2c075dbc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49da2ec7-f732-49f4-85ae-6ccc6724dfbd",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6b418f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'音声アシスタント'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "\n",
    "inputs = tokenizer.encode_plus(asr_text, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = nlu_model(**inputs)\n",
    "\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "answer_text = tokenizer.decode(answer_tokens)\n",
    "\n",
    "answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99be18dc-7865-4d1f-800a-5e1c59f8e6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: 私は音声アシスタントです。この7月で5歳になりました。今札幌に住んでいます。昨日は帯広に出かけました。好きなイベントはバルーンフェスティバルです。好きな食べ物はバタークッキーで趣味はカヌーです。\n",
      "question: あなたの名前は\n",
      "answer: 音声アシスタント\n"
     ]
    }
   ],
   "source": [
    "print(f\"text: {text}\")\n",
    "print(f\"question: {asr_text}\")\n",
    "print(f\"answer: {answer_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe75212-0c22-4c03-93c5-b8279f6ea219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7385301f-bb0f-45f5-84ec-b81bfd6b165c",
   "metadata": {},
   "source": [
    "### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b86ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['音声アシスタント']\n",
      " > Processing time: 0.353074312210083\n",
      " > Real-time factor: 0.1767455635722923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_filepath = \"output.wav\"\n",
    "tts.tts_to_file(answer_text, file_path=tts_filepath, progress_bar=False, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd30ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "\n",
    "def sound():\n",
    "    y, sr = librosa.load(tts_filepath)\n",
    "    return IPython.display.Audio(data=y, rate=sr)\n",
    "\n",
    "sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
