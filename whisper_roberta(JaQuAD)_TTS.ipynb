{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdb8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45a5c68",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "### - ASR [whisper(OpenAI)](https://github.com/openai/whisper)\n",
    "### - NLU [thkkvui/xlm-roberta-base-finetuned-JaQuAD(HuggingFace)](https://huggingface.co/thkkvui/xlm-roberta-base-finetuned-JaQuAD)\n",
    "### - Record [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/#class-pyaudio)\n",
    "### - TTS [TTS(coqui-ai)](https://github.com/coqui-ai/TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06528ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8be5b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q openai-whisper\n",
    "!pip install -q torch\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0bf861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded62d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1415fad",
   "metadata": {},
   "source": [
    "## ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3d47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "asr_model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "090204b2",
   "metadata": {},
   "source": [
    "## NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e279b05",
   "metadata": {},
   "source": [
    "## load model (from huggingface hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_name = \"thkkvui/xlm-roberta-base-finetuned-JaQuAD\"\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(model_name).to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7f46b",
   "metadata": {},
   "source": [
    "## load model (from local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a5b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "nlu_model = (AutoModelForQuestionAnswering.from_pretrained(\"./output\").to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c832aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d2c87",
   "metadata": {},
   "source": [
    "## 性能確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28457fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問: 昨日はどこへ出かけましたか？ -> 回答: 帯広\n",
      "質問: あなたの名前は何ですか？ -> 回答: 音声アシスタント\n",
      "質問: 何歳ですか？ -> 回答: 5歳\n",
      "質問: あなたの趣味を教えてください。 -> 回答: カヌー\n",
      "質問: あなたが好きなイベントは何ですか？ -> 回答: バルーンフェスティバル\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "私は音声アシスタントです。\\n\n",
    "この7月で5歳になりました。\\n\n",
    "今札幌に住んでいます。\\n\n",
    "昨日は帯広に出かけました。\\n\n",
    "好きなイベントはバルーンフェスティバルです。\\n\n",
    "好きな食べ物はバタークッキーです。\\n\n",
    "趣味はカヌーです。\n",
    "\"\"\"\n",
    "\n",
    "questions = [\"昨日はどこへ出かけましたか？\", \n",
    "             \"あなたの名前は何ですか？\", \n",
    "             \"何歳ですか？\",\n",
    "             \"あなたの趣味を教えてください。\", \n",
    "             \"あなたが好きなイベントは何ですか？\"]\n",
    "\n",
    "for question in questions:\n",
    "    \n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = nlu_model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    print(f\"質問: {question} -> 回答: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bc99430",
   "metadata": {},
   "source": [
    "## Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d048ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions\n",
    "\n",
    "# \"昨日はどこへ出かけましたか？\"\n",
    "# \"あなたの名前は何ですか？\"\n",
    "# \"何歳ですか？\"\n",
    "# \"あなたの趣味を教えてください。\"\n",
    "# \"あなたが好きなイベントは何ですか？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6c6ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak to your microphone for 8 sec...\n",
      "Great!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "record_time = 8\n",
    "record_filepath = \"record.wav\"\n",
    "\n",
    "FORMAT = pyaudio.paInt16        \n",
    "rate = 44100\n",
    "chunk = 2**11        \n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    input=True,\n",
    "                    rate=rate, \n",
    "                    frames_per_buffer=chunk,\n",
    "                    channels=1,\n",
    ")\n",
    "\n",
    "print(f\"Speak to your microphone for {record_time} sec...\")\n",
    "frames = []\n",
    "for i in range(0, int(rate / chunk * record_time)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data) \n",
    "print (\"Great!\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "wf = wave.open(record_filepath, 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6d458d",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d77154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q mecab-python3\n",
    "!pip install -q alkana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd64c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text = asr_model.transcribe(record_filepath, verbose=False, language=\"ja\")\n",
    "print(f'{asr_text[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82352927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昨日 は どこ へ 出かけ まし た か \n",
      "\n",
      "  word  en_word katakana\n",
      "0   昨日    False     None\n",
      "1    は    False     None\n",
      "2   どこ    False     None\n",
      "3    へ    False     None\n",
      "4  出かけ    False     None\n",
      "5   まし    False     None\n",
      "6    た    False     None\n",
      "7    か    False     None\n",
      "8   \\n    False     None\n",
      " \n",
      "昨日はどこへ出かけましたか\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import alkana\n",
    "import pandas as pd\n",
    "\n",
    "# トークン化\n",
    "al_re = re.compile(r'^[a-zA-Z]+$')\n",
    "def is_al(text):\n",
    "    return al_re.match(text) is not None\n",
    "\n",
    "tmp_text = asr_text[\"text\"] #\"helloテレビを見ました\"\n",
    "wakati = MeCab.Tagger('-Owakati')\n",
    "wakati_output = wakati.parse(tmp_text)\n",
    "print(wakati_output)\n",
    "\n",
    "\n",
    "# 英語検索\n",
    "df = pd.DataFrame(wakati_output.split(\" \"),columns=[\"word\"])\n",
    "df[\"en_word\"] = df[\"word\"].apply(is_al)\n",
    "df[\"katakana\"] = df[\"word\"].apply(alkana.get_kana)\n",
    "print(df)\n",
    "print(\" \")\n",
    "# カタカナ変換\n",
    "df = df[df[\"en_word\"] == True]\n",
    "dict_rep = dict(zip(df[\"word\"], df[\"katakana\"]))\n",
    "\n",
    "if len(df) > 0:\n",
    "    for word, katakana in dict_rep.items():\n",
    "        asr_text = tmp_text.replace(word, katakana)\n",
    "else:\n",
    "    asr_text = tmp_text\n",
    "    \n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152c5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b868f6b",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26a45b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールのインストール\n",
    "\n",
    "!pip install -q TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b0da8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# Japanese\n",
    "TTS.list_models()[38] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9c30be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download model\n",
    "model_name = TTS.list_models()[38]\n",
    "tts = TTS(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16238b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd6b418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "\n",
    "inputs = tokenizer.encode_plus(asr_text, text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = nlu_model(**inputs)\n",
    "\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "answer_tokens = inputs.input_ids[0, answer_start : answer_end + 1]\n",
    "answer_text = tokenizer.decode(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4b86ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['帯広']\n",
      " > Processing time: 0.13511395454406738\n",
      " > Real-time factor: 0.10114281293103904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_filepath = \"output.wav\"\n",
    "tts.tts_to_file(answer_text, speaker=tts.speakers, language=tts.languages, file_path=tts_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfd30ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "\n",
    "def sound():\n",
    "    y, sr = librosa.load(f\"{tts_filepath}\")\n",
    "    return IPython.display.Audio(data = y, rate=sr, autoplay=True)\n",
    "\n",
    "sound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f9ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
